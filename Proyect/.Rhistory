cube <- function(x, n) {
x^3
}
cube(3)
x <- 1:10
if(x > 5) {
x <- 0
}
f <- function(x) {
g <- function(y) {
y + z
}
z <- 4
x + g(x)
}
f
f()
z <- 10
f(3)
f <- function(x) {
g <- function(y) {
y + z
}
z <- 4
x + g(x)
}
z <- 10
f(3)
x <- 5
y <- if(x < 3) {
NA
} else {
10
}
y
h <- function(x, y = NULL, d = 3L) {
z <- cbind(x, d)
if(!is.null(y))
z <- z + y
else
z <- z + f
g <- x + y / z
if(d == 3L)
return(g)
g <- g + 10
g
}
h
h()
x <- c(rnorm(10), runif(10), rnorm(10, 1))
x
f <- gl(3, 10)
f
tapply(x, f, mean)
tapply(x, f, mean, simplify = false)
tapply(x, f, mean, simplify = FALSE)
tapply(x, f, rangue, simplify = FALSE)
tapply(x, f, range, simplify = FALSE)
tapply(x, f, range, simplify = TRUE)
x <- c(rnorm(10), runif(10), rnorm(10, 1))
x
f <- gl(3, 10)
f
split(x, f)
tapply(split(x,f), mean)
lapply(split(x,f), mean)
tapply(x, y, mean)
tapply(x, f, mean)
library(dataset)
library(datasets)
head(airquality)
head(airquality)
s <- split(airquality, airqualitu$Month)
s <- split(airquality, airquality$Month)
s
lapply(s, function(x), colMeans(, c(""Oozne, Solar. R, Wind)))
lapply(s, function(x), colMeans(, c(""Ozone, Solar. R, Wind)))
lapply(s, function(x), colMeans(, c(""Ozone, Solar.R, Wind)))
lapply(s, function(x), colMeans(, c("Ozone", "Solar.R", "Wind")))
lapply(s, function(x), colMeans(X[, c("Ozone", "Solar.R", "Wind")]))
lapply(s, function(x), colMeans(x[, c("Ozone", "Solar.R", "Wind")]))
lapply(s, function(x) colMeans(x[, c("Ozone", "Solar.R", "Wind")]))
s <- split(airquality, airquality$Day)
s
sapply(s, function(x) colMeans(x[, c("Ozone", "Solar.R", "Wind")]))
s <- split(airquality, airquality$Mounth)
s <- split(airquality, airqualitu$Month)
s <- split(airquality, airqualitu$Month)
s <- split(airquality, airquality$Month)
sapply(s, function(x) colMeans(x[, c("Ozone", "Solar.R", "Wind")]))
sapply(s, function(x) colMeans(x[, c("Ozone", "Solar.R", "Wind")]), na.rm=TRUE)
sapply(s, function(x) colMeans(x[, c("Ozone", "Solar.R", "Wind")], na.rm=TRUE))
x <- rnorm(10)
x
f1 <- gl(2,5)
f2<-gl(5,2)
interaction(f1,f2)
str(split(x, list(f1, f2)))
str(split(x, list(f1, f2), drop = true))
str(split(x, list(f1, f2), drop = TRUE))
str(split(x, list(f1)))
str(split(x, list(f2)))
list(rep(1, 4), rep(3,2), rep(4, 1))
mapply(rep, 1:4, 4:1)
noise <- function(n, mean, sd)
noise
noise <- function(n, mean, sd)
rnorm(n, mean, sd)
noise <- function(n, mean, sd){}
noise <- function(n, mean, sd){rnorm(n, mean, sd)}
noise(5, 1, 2)
noise(1:5, 1:5, 2)
mapply(noise, 1:5, 1:5, 2)
mapply(noise, 1:5, 1:5, 1)
mapply(noise, 1:5, 1:1, 1)
mapply(noise, 1:1, 1:1, 1)
mapply(noise, 1:2, 1:2, 1)
mapply(noise, 1:3, 1:2, 5)
mapply(noise, 1:3, 1:2, 3)
mapply(noise, 1:3, 1:2, 1)
mapply(noise, 1:3, 1:3, 1)
mapply(noise, 1:3, 1:3, 6)
mapply(noise, 1:3, 1:3, 2)
mapply(noise, 1:3, 1:3, 2)
library(datasets)
data(iris)
?iris
data(iris)
?iris
Sepal.Length
install.packages("RMySQL", type = "source")
ucscDb <- dbConnect(MySQL(),user="genome",
host="genome-mysql.cse.ucsc.edu")
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github", "56b637a5baffac62cad9")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
##Step1. Merges the training and the test sets to create one data set.
setwd("C:/Users/juan/Dropbox/Coursera/Ciesncia de datos(Especializacion)/Getting and Cleaning Data/Week3/Assessments/Proyect")
getwd()
##Read file X_train.txt
trainX <- read.table("./train/X_train.txt")
dim(trainX)
head(trainX)
##Read file y_train.txt
trainY <- read.table("./train/y_train.txt")
table(trainY)
##Read file subject_train.txt
trainSubject <- read.table("./train/subject_train.txt")
##Read file X_test.txt
testX <- read.table("./test/X_test.txt")
##Read file y_test.txt
testY <- read.table("./test/y_test.txt")
##Read file y_test.txt
testSubject <- read.table("./test/subject_test.txt")
##Combine trainX and testX
joinX <- rbind(trainX, testX)
##Combine trainY and testY
joinY <- rbind(trainY, testY)
##Combine trainSubject and testSubject
joinSubject <- rbind(trainSubject, testSubject)
# Step2. Extracts only the measurements on the mean and standard
# deviation for each measurement.
##Read file features.txt
features <- read.table("features.txt")
meanStdIndices <- grep("mean\\(\\)|std\\(\\)", features[, 2])
joinX <- joinX[, meanStdIndices]
names(joinX) <- gsub("\\(\\)", "", features[meanStdIndices, 2])
names(joinX) <- gsub("mean", "Mean", names(joinX))
names(joinX) <- gsub("std", "Std", names(joinX))
names(joinX) <- gsub("-", "", names(joinX))
# Step3. Uses descriptive activity names to name the activities in
# the data set
##Read file activity_labels.txt
activity <- read.table("./activity_labels.txt")
activity[, 2] <- tolower(gsub("_", "", activity[, 2]))
substr(activity[2, 2], 8, 8) <- toupper(substr(activity[2, 2], 8, 8))
substr(activity[3, 2], 8, 8) <- toupper(substr(activity[3, 2], 8, 8))
activityLabel <- activity[joinY[, 1], 2]
joinY[, 1] <- activityLabel
names(joinY) <- "activity"
# Step4. Appropriately labels the data set with descriptive activity
# names.
names(joinSubject) <- "subject"
cleanedData <- cbind(joinSubject, joinY, joinX)
# Step5. Creates a second, independent tidy data set with the average of
# each variable for each activity and each subject.
subjectLen <- length(table(joinSubject))
activityLen <- dim(activity)[1]
columnLen <- dim(cleanedData)[2]
result <- matrix(NA, nrow=subjectLen*activityLen, ncol=columnLen)
result <- as.data.frame(result)
colnames(result) <- colnames(cleanedData)
row <- 1
for(i in 1:subjectLen) {
for(j in 1:activityLen) {
result[row, 1] <- sort(unique(joinSubject)[, 1])[i]
result[row, 2] <- activity[j, 2]
bool1 <- i == cleanedData$subject
bool2 <- activity[j, 2] == cleanedData$activity
result[row, 3:columnLen] <- colMeans(cleanedData[bool1&bool2, 3:columnLen])
row <- row + 1
}
}
write.table(result, "dataClean.txt")
